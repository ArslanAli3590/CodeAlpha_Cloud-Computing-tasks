{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnVLctUg7gsz",
        "outputId": "f1d1858d-52ca-4e3c-b4ea-2d0c390a1a41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original Data (with duplicates):\n",
            "   id     name             email\n",
            "0   1    Alice    alice@mail.com\n",
            "1   2      Bob      bob@mail.com\n",
            "2   3  Charlie  charlie@mail.com\n",
            "3   4    David    david@mail.com\n",
            "4   2      Bob      bob@mail.com\n",
            "5   3  Charlie  charlie@mail.com\n",
            "\n",
            " Duplicates Found:\n",
            "   id     name             email\n",
            "1   2      Bob      bob@mail.com\n",
            "2   3  Charlie  charlie@mail.com\n",
            "4   2      Bob      bob@mail.com\n",
            "5   3  Charlie  charlie@mail.com\n",
            "\n",
            " Cleaned Data (Only Unique Records):\n",
            "   id     name             email\n",
            "0   1    Alice    alice@mail.com\n",
            "1   2      Bob      bob@mail.com\n",
            "2   3  Charlie  charlie@mail.com\n",
            "3   4    David    david@mail.com\n",
            "\n",
            " New Incoming Data:\n",
            "   id   name           email\n",
            "0   5    Eve    eve@mail.com\n",
            "1   6    Bob    bob@mail.com\n",
            "2   7  Frank  frank@mail.com\n",
            "\n",
            " Data After Validation (only unique kept):\n",
            "   id   name           email\n",
            "0   5    Eve    eve@mail.com\n",
            "2   7  Frank  frank@mail.com\n",
            "\n",
            " Final Database (with no redundancy):\n",
            "   id     name             email\n",
            "0   1    Alice    alice@mail.com\n",
            "1   2      Bob      bob@mail.com\n",
            "2   3  Charlie  charlie@mail.com\n",
            "3   4    David    david@mail.com\n",
            "4   5      Eve      eve@mail.com\n",
            "5   7    Frank    frank@mail.com\n",
            "\n",
            " Data saved to cleaned_database.csv\n"
          ]
        }
      ],
      "source": [
        "#  TASK 1: Data Redundancy Removal System\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 1: Load Dataset (simulate redundancy)\n",
        "# -------------------------------\n",
        "data = {\n",
        "    \"id\": [1, 2, 3, 4, 2, 3],\n",
        "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Bob\", \"Charlie\"],\n",
        "    \"email\": [\n",
        "        \"alice@mail.com\",\n",
        "        \"bob@mail.com\",\n",
        "        \"charlie@mail.com\",\n",
        "        \"david@mail.com\",\n",
        "        \"bob@mail.com\",\n",
        "        \"charlie@mail.com\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\" Original Data (with duplicates):\")\n",
        "print(df)\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 2: Identify Duplicates\n",
        "# -------------------------------\n",
        "duplicates = df[df.duplicated(subset=[\"name\", \"email\"], keep=False)]\n",
        "print(\"\\n Duplicates Found:\")\n",
        "print(duplicates)\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 3: Remove Redundancy\n",
        "# -------------------------------\n",
        "unique_df = df.drop_duplicates(subset=[\"name\", \"email\"], keep=\"first\")\n",
        "print(\"\\n Cleaned Data (Only Unique Records):\")\n",
        "print(unique_df)\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 4: Validation Before Adding New Data\n",
        "# -------------------------------\n",
        "# Suppose new incoming data\n",
        "new_data = pd.DataFrame([\n",
        "    {\"id\": 5, \"name\": \"Eve\", \"email\": \"eve@mail.com\"},          # ✅ Unique\n",
        "    {\"id\": 6, \"name\": \"Bob\", \"email\": \"bob@mail.com\"},          # ❌ Duplicate\n",
        "    {\"id\": 7, \"name\": \"Frank\", \"email\": \"frank@mail.com\"}       # ✅ Unique\n",
        "])\n",
        "\n",
        "print(\"\\n New Incoming Data:\")\n",
        "print(new_data)\n",
        "\n",
        "# Validation: Add only if not already present\n",
        "validated_data = new_data[\n",
        "    ~new_data.set_index([\"name\", \"email\"]).index.isin(unique_df.set_index([\"name\", \"email\"]).index)\n",
        "]\n",
        "\n",
        "print(\"\\n Data After Validation (only unique kept):\")\n",
        "print(validated_data)\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 5: Append Unique Data into Final Database\n",
        "# -------------------------------\n",
        "final_df = pd.concat([unique_df, validated_data]).reset_index(drop=True)\n",
        "\n",
        "print(\"\\n Final Database (with no redundancy):\")\n",
        "print(final_df)\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 6: Save to CSV (simulate cloud storage)\n",
        "# -------------------------------\n",
        "final_df.to_csv(\"cleaned_database.csv\", index=False)\n",
        "print(\"\\n Data saved to cleaned_database.csv\")\n"
      ]
    }
  ]
}